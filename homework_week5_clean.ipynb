{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wlu-s2k9D1Ba"
   },
   "source": [
    "### Homework 5: Question search engine\n",
    "\n",
    "Remeber week01 where you used GloVe embeddings to find related questions? That was.. cute, but far from state of the art. It's time to really solve this task using context-aware embeddings.\n",
    "\n",
    "__Warning:__ this task assumes you have seen `seminar.ipynb`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "HYffoHiI8du5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/mitc/nadejda/venv/lib/python3.10/site-packages (4.57.0)\n",
      "Requirement already satisfied: datasets in /home/mitc/nadejda/venv/lib/python3.10/site-packages (4.1.1)\n",
      "Requirement already satisfied: accelerate in /home/mitc/nadejda/venv/lib/python3.10/site-packages (1.10.1)\n",
      "Requirement already satisfied: deepspeed in /home/mitc/nadejda/venv/lib/python3.10/site-packages (0.17.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from transformers) (2025.9.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from transformers) (0.22.0)\n",
      "Requirement already satisfied: requests in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from transformers) (0.35.0)\n",
      "Requirement already satisfied: filelock in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: xxhash in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: pandas in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from datasets) (2.3.2)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: fsspec[http]<=2025.9.0,>=2023.1.0 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from datasets) (2025.9.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: psutil in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from accelerate) (2.5.1+cu121)\n",
      "Requirement already satisfied: hjson in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from deepspeed) (3.1.0)\n",
      "Requirement already satisfied: pydantic>=2.0.0 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from deepspeed) (2.11.9)\n",
      "Requirement already satisfied: py-cpuinfo in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from deepspeed) (9.0.0)\n",
      "Requirement already satisfied: msgpack in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from deepspeed) (1.1.1)\n",
      "Requirement already satisfied: nvidia-ml-py in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from deepspeed) (13.580.82)\n",
      "Requirement already satisfied: ninja in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from deepspeed) (1.13.0)\n",
      "Requirement already satisfied: einops in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from deepspeed) (0.8.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from pydantic>=2.0.0->deepspeed) (0.7.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from pydantic>=2.0.0->deepspeed) (0.4.2)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from pydantic>=2.0.0->deepspeed) (2.33.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from requests->transformers) (2025.8.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: jinja2 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: networkx in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.1.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->accelerate) (12.8.93)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.6.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch in /home/mitc/nadejda/venv/lib/python3.10/site-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: torchvision in /home/mitc/nadejda/venv/lib/python3.10/site-packages (0.20.1+cu121)\n",
      "Requirement already satisfied: torchaudio in /home/mitc/nadejda/venv/lib/python3.10/site-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: fsspec in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: filelock in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: jinja2 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: networkx in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.8.93)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mitc/nadejda/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade transformers datasets accelerate deepspeed\n",
    "!pip install -U torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import transformers\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HfSHyQlT-fVF"
   },
   "source": [
    "### Load data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383,
     "referenced_widgets": [
      "57de84ef7f654d91b59a48a37964d5fe",
      "95730d140e854bf9afe239eba48b8ecc",
      "26772a5cce6e48e1b898bfea25e0ccdf",
      "c506382332dc41c7b1f86e3c3ad0308b",
      "ac83bef6310b4c77ac44f4c19f0faf72",
      "2ce8503172994a6fbcba04219cbd9f21",
      "0977541b6d734c67b7ee6c6b4b2738e9",
      "ab0dc315efb544e9aff2a0eac38f3766",
      "f4e13bb61cae4148873f3cc675b4190d",
      "877e2a4a7c194e7aa376652aa6bf9db8",
      "540313269f124b3c937320c709fcae43",
      "f28178de7ce24bc5b970322df3951f57",
      "c11dc4ca607d460a98ceaef21d54e3a1",
      "f53f5d35526c4df0807f53edf786d243",
      "8e38200a76af4c77a23475c79839a21c",
      "f0c3c1188f0d4c3ca8e486aa546bf5d9",
      "1027f0a59f0c43bf9b7f0842b0b22450",
      "a7ed0cb8196c449ea19b9c431f5a67c5",
      "eca7f55f81874d1e947130d3ef348eab",
      "cbcbb98b92b1466bbae4238769e3129a",
      "2dd13da7d7d14f41b93aee0cc29848fa",
      "f0d4c8992051441d92d135546892a2f1",
      "567d8820239d4517a874e90fe6846744",
      "1bea41ee94f94e3ab3cbaaaeb4467a8f",
      "5b5518cada284238b452b7ac2438d621",
      "11fcc4b4540a4b8f9ab516df63d82fe4",
      "d9b1bbbd59a24ab7978c2301ede0c323",
      "243955334b244c48bf7976fac3e73db6",
      "5ee168c2a97b4f42b9a7144d1406ce8d",
      "49b83ddc9752492799e9e83fc8323bd9",
      "a24b9ee16e57449fbf6c426bb990cb16",
      "5759667815b5413f99bcac33f7839d1e",
      "1f1d5c321cd7407f87e14a9276ae390d",
      "f8f36bfb069041ffa8cbeed66d12a7dc",
      "92187d522a1443d98100cb74722ace59",
      "a1fd0c3febb94d0b9913e3576e9a4c6e",
      "ec0c7e2c7dbf447181a2b896269a6332",
      "88efef988efc4e2a94a4a2a4c5aace35",
      "ccc9c84aeb894a47ad3fb0e5951a14f1",
      "440378a65b7f4911b25d77e585ba662a",
      "f4ad4dd6600847a2abd562e49a3722b4",
      "706e6abf1213426d9fc4989d5c29ef67",
      "0646630340f4431695d866d9c4d907d4",
      "4cd3362b9f6a49c38474c78c85276c9f",
      "0cb95e6659a44b2b9184143b0d54b3c6",
      "4979b6198a184ce0ba32ef7593e52b90",
      "ab623dca7bc1484c81a8e660b54f1fb9",
      "47fc9f2670c34d5c80475dffdf003675",
      "153b2610ac7245b286bf0d4c09cae6a5",
      "b37d40d2957e4a16ab4295a054e554ce",
      "dd2bce7d2f63495387af1ec53951b24a",
      "d667040fe58e4509800c5d681fc3530c",
      "c5207dad43814d1eb6e3a9fdb1ffbcc2",
      "f0cd589e36b7411f8125825ebeada588",
      "e6aebc5a19a24e2295dcbcd0471aae43",
      "08374dcc0add4422876534bbc3df0210",
      "6dbe5b0022b243768ff1fb6380b15701",
      "8f6679cba6f34690a1cbe0caf1ccc667",
      "7288874d56824884a381a934f7d0120b",
      "8273db6eaf60480db37b7b4661cfcd35",
      "062f09ea6fb948e6b8e277bb781776f7",
      "fdeba677dd204e328b432206260bee35",
      "66051254e1784255a89f562703df5ee6",
      "07795d75d16e45339fb0295f14fce673",
      "75054475bf7948ab814f876edfc26d82",
      "76bc67f258e048eeba64259c46ff2fa2",
      "7940e5e82f5d4729a35c06c1ddfe1edb",
      "b474c61db0f548d6a36fe364ba7adc81",
      "a9cbb1b2b2b64fabb234af3eda4bda7d",
      "e1af42c4622c46a590d4a69dab0052ef",
      "9c2e02db4efc4b40856491ee82d30344",
      "dc4a2e62c01145fcb104581da8ef82ef",
      "4bf8c73310484175b565c668f6993c23",
      "755e43386a44413db58ce2212e224afd",
      "6f063b0b5d544eaca498048545a6e935",
      "c92aba9883804f68bc263c8304c7a4ef",
      "044b2d9bf5bf4c03b4b39e5e67dea73a",
      "5b1570cc7af0407ca1373b777dc49013",
      "540de3807f494b55838405b752863581",
      "c22a553ad6454f56be2717ca4325eb17",
      "02dc5e3eb101442aa76eccb62776abb1",
      "f7cf32574b8e449ab785772d07be5d8c",
      "66684599ea2b42baac28748bb61971f0",
      "6723deac6a2f4d94bf31f2b3c273d238",
      "efcc6541c199448cb3323319f43dd56f",
      "5a0042b1cfe7407bb9819dd74ff52d82",
      "db84b18842694c3f8de509fe6ca5388b",
      "58d1cc219c5c47e495b16954d0434fd8",
      "babb621147e24250ab570e930b84a935",
      "1c7a1d1014394405856d364982c32aff",
      "61ba6bb4d536430b8f2846b0118fd5fd",
      "95c394228d814f8bbb182915532531c9",
      "e76d3c61cdd441c2a89aeba87c4f468c",
      "cc202c695d034adb8e81f53c1822df56",
      "3585e1692b8549ad80419253465eda34",
      "fe10a8ff01874724b4a08a389747e972",
      "5b14308db2564fa3ac3cf459f60fc5b3",
      "75f8dc350e4f4f7c94514f7630cfd67a",
      "7729b8b0444741b497fb1171806b64e7",
      "e6ae0c29e17a4f93b9fe1129ed03f671",
      "12b38dad93d147ebbbabeedb91c76f61",
      "b46f0a7d95884225ab57efef57aa4f0f",
      "c8b067bb794e446b8af138b60b7b841c",
      "5491722c8bea496ebe996bba24313daa",
      "6338ece324484b7786d01513968ebd0e",
      "71df099ffdc342979565fedead05ef3b",
      "7e761dae857d4a69b92fdc102d1cc878",
      "bf7421b38fab48fda6d73be484d1a742",
      "2b1ecf8a98d54a5cbf875e686cd855f7",
      "647e943f9520413ab57ad11c1f6d7d76"
     ]
    },
    "id": "Y2_wgtrx8e6C",
    "outputId": "e0ccfe0f-3bbe-45b6-dbce-ebb3c306f0b4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Sample[0]: {'text1': 'How is the life of a math student? Could you describe your own experiences?', 'text2': 'Which level of prepration is enough for the exam jlpt5?', 'label': 0, 'idx': 0, 'label_text': 'not duplicate'}\n",
      "Sample[3]: {'text1': 'What can one do after MBBS?', 'text2': 'What do i do after my MBBS ?', 'label': 1, 'idx': 3, 'label_text': 'duplicate'}\n"
     ]
    }
   ],
   "source": [
    "qqp = datasets.load_dataset('SetFit/qqp')\n",
    "print('\\n')\n",
    "print(\"Sample[0]:\", qqp['train'][0])\n",
    "print(\"Sample[3]:\", qqp['train'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209,
     "referenced_widgets": [
      "5665fb86aff9467094ed45886171c7df",
      "7315fdb53854440593151e4fa744c84e",
      "7bcd7e5237b24170b34e9f05859c83d4",
      "b9a755af183e47bd8f8dd87835944a11",
      "e15dec406e96405e8195570422c669bf",
      "630a0182bed84f7faefb3d9ce5d80992",
      "e7b6c902798c4662a094475712d05d33",
      "e1f6442e0514427d929df5eb3ed2fd09",
      "4b45811d0a1743ecac1bcee24229a9d1",
      "277e8524581c43c1b9cfb50e961ffd97",
      "38138f1757074ed8bb732dc8de2c3bdc",
      "93b507ac0db744f39dcef593990274fa",
      "eec7373e7af64f4e9c7c4a23e251a50d",
      "4b8cbeb23aee439d979e427de4816587",
      "4277f0ae719c4591b2c44b74e8a71e83",
      "80037b0b186f4e0bacf30ae95f7ea6c6",
      "2db672e52e9b43e6948823698d72ffca",
      "8e17912080164855b92f5d3767c8a38e",
      "799ac98a0fdb4fec9945ed8a76e4c3e5",
      "6d4d5425d0274d4ba332aa8df882c1f8",
      "9bc1441cec7f4b969b279e44730c3f6e",
      "8dd0cf38fcca4eb8973d400b72e9a6dc",
      "be62ce0275c84690bd467a3647499645",
      "615a2a44d978411e83cbf72f5f52851d",
      "d502271ba8c742b0873503d5ee486ae6",
      "ec31bc96bf004b79ac4ecb05a0dea9be",
      "7580e8f4f7c54898a65fab2e742facb2",
      "7ae9b172220b4ba091167334f83509a5",
      "490c5c0a20424e28b23e598c45ec2f8f",
      "dbb790f8941c4f8aa4c555c032653450",
      "1d1bb661b0e4403ea410811c8a275da2",
      "45a8539937c84fdda9a14c69ba8ee5b1",
      "055156e2a02f4102a4c94a284551ed6d",
      "c7a3dc15d88f4fc2ae2653e759197d91",
      "e2f106ae1c464052b0c1fcc7c51adf80",
      "5b51762cc3254bafb8016174e3a2569a",
      "236243af6d7f4caf82d2e61c6d59ba2b",
      "7cb20bb1e19c4225a1ca2dec9333828c",
      "90dc3c700e4443ba84bea7713149c5d2",
      "735a5293cb904174afbf249d7b211c4a",
      "aab20d71f1324477a982df3cc1f6a3ff",
      "34d3bfe88aa54e8c8e6e8e7754d33050",
      "7714501bcc3e4131b668c54d47d3700e",
      "7d263c6c74d2480b85c9e0f3b7c5dfa1",
      "97de52577eb6476ebbfd3b4bf99d3525",
      "802f0462bb044e08812bd1ed9569491a",
      "2b91b138f0f44aa887fd372a7721b98f",
      "703c15efbad148158e071f3b27d3a993",
      "a9370efad9714889bfd0bab19e4596ba",
      "4517afc0b28946ee927e5ec6deb7d80b",
      "5aca173fe03e45f39baeda0cc4d025c0",
      "fcce9beea0e14fb5a8d2b7394b058341",
      "3987ec42fa2649e7815c6695bd685480",
      "585d35345bf1463b981e02d47aebab44",
      "76ab7294c3614825b56464c4dea051f7",
      "ebc1644fc64940f68aef6b6b65b349d4",
      "fb78c338c9bf4c40b35bd7f396e58f14",
      "197a695274e6481dbe4491213a8bc8a3",
      "6512eb2747574064b84e6b4e931db9c7",
      "30fa5b8d9bbb43dd8e286a8577fcf09c",
      "84c012740172430bba8a467167612ba2",
      "861ecbae8e874186a890a707b7c0be15",
      "94b28b7c94204dc890084a5cb2049b9b",
      "d91dbc5fb50b49cdb30ef5843c1b705d",
      "9ec5c8a95e4c4c1bb9fb3808fd1d70a2",
      "6340950f04624fd192924b175b1a12c3"
     ]
    },
    "id": "pStlWcvD8rdk",
    "outputId": "a7761dea-a92d-4cf4-a086-4bd486f4ec9d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-06 12:19:48.125128: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-06 12:19:48.152485: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-06 12:19:48.901133: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"gchhablani/bert-base-cased-finetuned-qqp\"\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n",
    "model = transformers.AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"gchhablani/bert-base-cased-finetuned-qqp\",\n",
    "    use_safetensors=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hM3ZujeZ-Z7E"
   },
   "source": [
    "### Tokenize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "12c12df2494c44c0a935c410bcd6e088",
      "c09b23f048944abdac203f2c46ca84a1",
      "52707d2f74f64704aed6c959550aa837",
      "f22e7ac95b374f948d59cb1acc1a407b",
      "724302898aac4f7186507b2612f3c166",
      "00e75a045120410cb5bae6337786fe5b",
      "8cdbd794bb654ceba2f73b135ff51b89",
      "b681db0308da4814ab041f8f34dcfa91",
      "cff3a35530d34374a39e61f1a177bf2d",
      "ef512c2d8bbb49adbfec24f2bf09aa31",
      "6a1dbaa3bd0f4e4481b11db157f7166f",
      "c340cf51781d49779f65d3115e20e682",
      "cc8215d237bc49cc85ad40f23c266af7",
      "3088610ae689402c844b6e1e462acffa",
      "6ef5444cc4fb474ca2717c3ed41e942a",
      "ab8b051ae898453b8611cb13f84785ec",
      "660e9f2f5e6a4483b5ccfb040e4bc411",
      "e44b0f66ecb04de99f95f7babfd34cb2",
      "339ba1fa076c44f4ac32f3262dda4276",
      "152bea4a788f46db9a4854c08afa0dec",
      "6157c724f48f42ada0ca42d5b207a825",
      "d7300570db3d424596202f68c915ce07",
      "781f38c4f2fe4cf3bdc83094067b0d54",
      "ffd94b5f90bd436f92406897898f680a",
      "7256e6cb25344a9bb4321ef0f8148578",
      "d0804a4659d444cfb5da564d897dd004",
      "fb3cba50bc3c4b43bec72e4c4e9391de",
      "5fd2b9cb0b7b41a98c1a767a3d357b36",
      "671aabb739a24b53afd5c610486b5931",
      "87a0ec65665c4c818bbe50b96b9ccbdf",
      "4e160a221a904d14a4442d3b7107fc9b",
      "6dff62a4187344269fc2c7b52ca493be",
      "1c839267e0b8492f878e9ba4c2f69f47"
     ]
    },
    "id": "qtkllSPG9bTL",
    "outputId": "7940d7b3-f362-45f9-9da2-41f0084f58b4"
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 128\n",
    "def preprocess_function(examples):\n",
    "    result = tokenizer(\n",
    "        examples['text1'], examples['text2'],\n",
    "        padding='max_length', max_length=MAX_LENGTH, truncation=True\n",
    "    )\n",
    "    result['label'] = examples['label']\n",
    "    return result\n",
    "\n",
    "qqp_preprocessed = qqp.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ObMcFN59_Ll2",
    "outputId": "174e7cdd-de86-45ac-9a58-4cbb9c6ca45d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 1731, 1110, 1103, 1297, 1104, 170, 12523, 2377, 136, 7426, 1128, 5594, 1240, 1319, 5758, 136,  ...\n"
     ]
    }
   ],
   "source": [
    "print(repr(qqp_preprocessed['train'][0]['input_ids'])[:100], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PyQ1ZbzGAUF2"
   },
   "source": [
    "### Task 1: evaluation (1 point)\n",
    "\n",
    "We randomly chose a model trained on QQP - but is it any good?\n",
    "\n",
    "One way to measure this is with validation accuracy - which is what you will implement next.\n",
    "\n",
    "Here's the interface to help you do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "M5ueSoieAbBg"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_761130/212221521.py:36: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9084\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import default_data_collator\n",
    "\n",
    "# Load validation set\n",
    "val_set = qqp_preprocessed[\"validation\"]\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Create optimized DataLoader\n",
    "val_loader = DataLoader(\n",
    "    val_set,\n",
    "    batch_size=64,           # larger batch for speed\n",
    "    shuffle=False,\n",
    "    collate_fn=default_data_collator,\n",
    "    num_workers=4,           # parallel data loading\n",
    "    pin_memory=True          # faster transfer to GPU\n",
    ")\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Evaluate with no_grad and mixed precision for speed\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        token_type_ids = batch[\"token_type_ids\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        with autocast():\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                token_type_ids=token_type_ids\n",
    "            )\n",
    "            preds = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "val_accuracy = correct / total\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RoxHzxn0DQqO"
   },
   "source": [
    "__Your task__ is to measure the validation accuracy of your model.\n",
    "Doing so naively may take several hours. Please make sure you use the following optimizations:\n",
    "\n",
    "- run the model on GPU with no_grad\n",
    "- using batch size larger than 1\n",
    "- use optimize data loader with num_workers > 1\n",
    "- (optional) use [mixed precision](https://pytorch.org/docs/stable/notes/amp_examples.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "9k5EK7-KA5F2"
   },
   "outputs": [],
   "source": [
    "\n",
    "accuracy = val_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0R2z_-FZU3qy",
    "outputId": "bdccca39-2fc9-462c-b3a7-30b5fc9e86ad"
   },
   "outputs": [],
   "source": [
    "assert 0.9 < accuracy < 0.91"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KONQ1E0J-y6B"
   },
   "source": [
    "### Task 2: train the model (4 points)\n",
    "\n",
    "For this task, you have two options:\n",
    "\n",
    "__Option A:__ fine-tune your own model. You are free to choose any model __except for the original BERT.__ We recommend [DeBERTa-v3](https://huggingface.co/microsoft/deberta-v3-base). Better yet, choose the best model based on public benchmarks (e.g. [GLUE](https://gluebenchmark.com/)).\n",
    "\n",
    "You can write the training code manually or use transformers.Trainer (see [this example](https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification)). Please make sure that your model's accuracy is at least __comparable__ with the above example for BERT.\n",
    "\n",
    "\n",
    "__Option B:__ compare at least 3 pre-finetuned models (in addition to the above BERT model). For each model, report (1) its accuracy, (2) its speed, measured in samples per second in your hardware setup and (3) its size in megabytes. Please take care to compare models in equal setting, e.g. same CPU / GPU. Compile your results into a table and write a short (~half-page on top of a table) report, summarizing your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T0ZkZTkl_yMU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf-keras in /home/mitc/nadejda/venv/lib/python3.10/site-packages (2.20.1)\n",
      "Requirement already satisfied: tensorflow<2.21,>=2.20 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from tf-keras) (2.20.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.32.5)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.17.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (6.32.1)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.75.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.3.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.26.4)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: setuptools in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (65.5.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.20.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.14.0)\n",
      "Requirement already satisfied: packaging in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (25.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.17.3)\n",
      "Requirement already satisfied: keras>=3.10.0 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.11.3)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (4.15.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.1.0)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (25.2.10)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.5.3)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<2.21,>=2.20->tf-keras) (0.45.1)\n",
      "Requirement already satisfied: namex in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.1.0)\n",
      "Requirement already satisfied: optree in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.17.0)\n",
      "Requirement already satisfied: rich in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (14.1.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (2.5.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (3.4.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (2025.8.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (3.10)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.1.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.9)\n",
      "Requirement already satisfied: pillow in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (11.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/mitc/nadejda/venv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: sentencepiece in /home/mitc/nadejda/venv/lib/python3.10/site-packages (0.2.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: sentencepiece in /home/mitc/nadejda/venv/lib/python3.10/site-packages (0.2.1)\n",
      "Requirement already satisfied: protobuf in /home/mitc/nadejda/venv/lib/python3.10/site-packages (6.32.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|                                                                                                                | 0/363846 [00:00<?, ? examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:   1%|▌                                                                                                 | 2000/363846 [00:00<00:23, 15476.54 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:   2%|██▏                                                                                                | 8000/363846 [00:00<00:39, 9110.79 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:   4%|███▋                                                                                             | 14000/363846 [00:01<00:26, 13215.40 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:   4%|████▎                                                                                            | 16000/363846 [00:01<00:24, 13966.08 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:   8%|███████▍                                                                                         | 28000/363846 [00:01<00:21, 15792.64 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:   8%|███████▉                                                                                         | 30000/363846 [00:02<00:21, 15769.73 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  10%|█████████▌                                                                                       | 36000/363846 [00:02<00:20, 16062.35 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  12%|███████████▏                                                                                     | 42000/363846 [00:02<00:19, 16159.77 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  14%|█████████████▎                                                                                   | 50000/363846 [00:03<00:19, 16119.82 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  14%|█████████████▊                                                                                   | 52000/363846 [00:03<00:19, 16068.67 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  17%|████████████████▌                                                                                | 62000/363846 [00:04<00:22, 13715.68 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  18%|█████████████████                                                                                | 64000/363846 [00:04<00:20, 14343.76 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  19%|██████████████████▏                                                                              | 68000/363846 [00:04<00:19, 15171.96 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  19%|██████████████████▋                                                                              | 70000/363846 [00:04<00:19, 15414.40 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  21%|████████████████████▊                                                                            | 78000/363846 [00:05<00:17, 15919.81 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  23%|██████████████████████▍                                                                          | 84000/363846 [00:05<00:17, 16165.35 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  25%|███████████████████████▉                                                                         | 90000/363846 [00:06<00:16, 16158.75 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  28%|██████████████████████████▉                                                                     | 102000/363846 [00:06<00:16, 16284.31 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  29%|███████████████████████████▍                                                                    | 104000/363846 [00:06<00:16, 16126.23 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  31%|██████████████████████████████                                                                  | 114000/363846 [00:07<00:17, 14438.21 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  33%|███████████████████████████████▋                                                                | 120000/363846 [00:08<00:15, 15529.66 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  34%|████████████████████████████████▋                                                               | 124000/363846 [00:08<00:15, 15863.52 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  35%|█████████████████████████████████▏                                                              | 126000/363846 [00:08<00:14, 15921.32 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  35%|█████████████████████████████████▊                                                              | 128000/363846 [00:08<00:14, 15922.80 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  36%|██████████████████████████████████▎                                                             | 130000/363846 [00:08<00:14, 15960.15 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  36%|██████████████████████████████████▊                                                             | 132000/363846 [00:08<00:14, 15722.78 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  37%|███████████████████████████████████▎                                                            | 134000/363846 [00:08<00:14, 15700.66 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  37%|███████████████████████████████████▉                                                            | 136000/363846 [00:09<00:14, 15753.18 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  38%|████████████████████████████████████▍                                                           | 138000/363846 [00:09<00:14, 15834.20 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  38%|████████████████████████████████████▉                                                           | 140000/363846 [00:09<00:14, 15849.86 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  41%|███████████████████████████████████████▌                                                        | 150000/363846 [00:09<00:13, 16228.73 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  42%|████████████████████████████████████████                                                        | 152000/363846 [00:10<00:13, 16169.49 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  42%|████████████████████████████████████████▋                                                       | 154000/363846 [00:10<00:12, 16170.03 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  45%|██████████████████████████████████████████▋                                                     | 162000/363846 [00:10<00:14, 13731.51 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  45%|███████████████████████████████████████████▎                                                    | 164000/363846 [00:11<00:13, 14389.39 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  46%|███████████████████████████████████████████▊                                                    | 166000/363846 [00:11<00:13, 14879.50 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  49%|██████████████████████████████████████████████▉                                                 | 178000/363846 [00:11<00:11, 16133.06 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  54%|███████████████████████████████████████████████████▋                                            | 196000/363846 [00:13<00:10, 16131.97 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  54%|████████████████████████████████████████████████████▏                                           | 198000/363846 [00:13<00:10, 16087.75 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  55%|████████████████████████████████████████████████████▊                                           | 200000/363846 [00:13<00:10, 16009.15 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  56%|█████████████████████████████████████████████████████▎                                          | 202000/363846 [00:13<00:10, 16038.91 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  56%|█████████████████████████████████████████████████████▊                                          | 204000/363846 [00:13<00:09, 16048.38 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  58%|███████████████████████████████████████████████████████▉                                        | 212000/363846 [00:14<00:11, 13626.40 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  59%|████████████████████████████████████████████████████████▉                                       | 216000/363846 [00:14<00:09, 14827.87 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  63%|████████████████████████████████████████████████████████████▏                                   | 228000/363846 [00:15<00:08, 15813.05 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  63%|████████████████████████████████████████████████████████████▋                                   | 230000/363846 [00:15<00:08, 15907.03 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  64%|█████████████████████████████████████████████████████████████▏                                  | 232000/363846 [00:15<00:08, 16013.33 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  65%|██████████████████████████████████████████████████████████████▊                                 | 238000/363846 [00:15<00:07, 16134.64 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  67%|███████████████████████████████████████████████████████████████▊                                | 242000/363846 [00:16<00:07, 16137.08 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  67%|████████████████████████████████████████████████████████████████▍                               | 244000/363846 [00:16<00:07, 16036.76 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  68%|████████████████████████████████████████████████████████████████▉                               | 246000/363846 [00:16<00:07, 16030.73 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  70%|███████████████████████████████████████████████████████████████████▌                            | 256000/363846 [00:17<00:10, 10561.83 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  71%|████████████████████████████████████████████████████████████████████                            | 258000/363846 [00:17<00:09, 11701.88 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  73%|██████████████████████████████████████████████████████████████████████▏                         | 266000/363846 [00:17<00:06, 14708.43 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  74%|██████████████████████████████████████████████████████████████████████▋                         | 268000/363846 [00:17<00:06, 15118.46 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  74%|███████████████████████████████████████████████████████████████████████▏                        | 270000/363846 [00:18<00:06, 15404.62 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  75%|███████████████████████████████████████████████████████████████████████▊                        | 272000/363846 [00:18<00:05, 15610.08 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  76%|████████████████████████████████████████████████████████████████████████▊                       | 276000/363846 [00:18<00:05, 15841.89 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  78%|██████████████████████████████████████████████████████████████████████████▍                     | 282000/363846 [00:18<00:05, 15923.94 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  78%|██████████████████████████████████████████████████████████████████████████▉                     | 284000/363846 [00:18<00:05, 15850.37 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  80%|█████████████████████████████████████████████████████████████████████████████                   | 292000/363846 [00:19<00:04, 15983.18 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  81%|██████████████████████████████████████████████████████████████████████████████                  | 296000/363846 [00:19<00:04, 16087.77 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  82%|██████████████████████████████████████████████████████████████████████████████▋                 | 298000/363846 [00:19<00:04, 16058.57 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  82%|███████████████████████████████████████████████████████████████████████████████▏                | 300000/363846 [00:19<00:03, 15972.96 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  84%|████████████████████████████████████████████████████████████████████████████████▋               | 306000/363846 [00:20<00:05, 10554.92 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  86%|██████████████████████████████████████████████████████████████████████████████████▎             | 312000/363846 [00:20<00:03, 13656.91 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  86%|██████████████████████████████████████████████████████████████████████████████████▊             | 314000/363846 [00:21<00:03, 14304.15 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  88%|████████████████████████████████████████████████████████████████████████████████████▉           | 322000/363846 [00:21<00:02, 15727.22 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  91%|███████████████████████████████████████████████████████████████████████████████████████▌        | 332000/363846 [00:22<00:01, 16103.71 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  92%|████████████████████████████████████████████████████████████████████████████████████████▏       | 334000/363846 [00:22<00:01, 16091.90 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  94%|██████████████████████████████████████████████████████████████████████████████████████████▏     | 342000/363846 [00:22<00:01, 16125.69 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  95%|██████████████████████████████████████████████████████████████████████████████████████████▊     | 344000/363846 [00:22<00:01, 16078.81 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  95%|███████████████████████████████████████████████████████████████████████████████████████████▎    | 346000/363846 [00:23<00:01, 16072.99 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  96%|███████████████████████████████████████████████████████████████████████████████████████████▊    | 348000/363846 [00:23<00:00, 16009.28 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  97%|████████████████████████████████████████████████████████████████████████████████████████████▊   | 352000/363846 [00:23<00:00, 16043.83 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  98%|██████████████████████████████████████████████████████████████████████████████████████████████▍ | 358000/363846 [00:23<00:00, 11775.96 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 363846/363846 [00:24<00:00, 14935.28 examples/s]\n",
      "Map:   0%|                                                                                                                 | 0/40430 [00:00<?, ? examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:   5%|████▉                                                                                              | 2000/40430 [00:00<00:02, 15475.05 examples/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Map:  10%|█████████▊                                                                                         | 4000/40430 [00:00<00:02, 15757.27 examples/s]"
     ]
    }
   ],
   "source": [
    "# Fine-tune DeBERTa-v3 on QQP (binary classification)\n",
    "# Requirements: transformers datasets accelerate sklearn\n",
    "# pip install -U transformers datasets accelerate scikit-learn\n",
    "!pip install tf-keras\n",
    "!pip install --upgrade sentencepiece\n",
    "!pip install sentencepiece protobuf\n",
    "import sentencepiece\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import DebertaV2Tokenizer\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "MODEL_NAME = \"microsoft/deberta-v3-base\"  # or \"microsoft/deberta-v3-large\" if you have memory\n",
    "NUM_LABELS = 2\n",
    "BATCH_SIZE = 32    # adjust down if OOM; increase if you have more GPU memory\n",
    "EPOCHS = 3\n",
    "LR = 2e-5\n",
    "OUTPUT_DIR = \"./deberta_qqp_finetuned\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# 1) Load QQP (GLUE) dataset\n",
    "# If you already have preprocessed data, adapt collate/tokenization below to your dataset.\n",
    "raw = load_dataset(\"glue\", \"qqp\")\n",
    "# split names: 'train', 'validation', 'test' (test has no labels usually)\n",
    "train_ds = raw[\"train\"]\n",
    "val_ds = raw[\"validation\"]\n",
    "\n",
    "# 2) Tokenizer + model\n",
    "tokenizer = DebertaV2Tokenizer.from_pretrained(\"microsoft/deberta-v3-base\")\n",
    "\n",
    "def preprocess(examples):\n",
    "    # QQP columns: question1, question2\n",
    "    return tokenizer(\n",
    "        examples[\"question1\"],\n",
    "        examples[\"question2\"],\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "    )\n",
    "\n",
    "train_ds = train_ds.map(preprocess, batched=True, remove_columns=train_ds.column_names)\n",
    "val_ds   = val_ds.map(preprocess, batched=True, remove_columns=val_ds.column_names)\n",
    "\n",
    "# Ensure label column is named 'labels' for Trainer\n",
    "train_ds = train_ds.rename_column(\"label\", \"labels\")\n",
    "val_ds   = val_ds.rename_column(\"label\", \"labels\")\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=NUM_LABELS)\n",
    "model.to(device)\n",
    "\n",
    "# 3) Metrics\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    y_pred = np.argmax(preds, axis=1)\n",
    "    acc = accuracy_score(labels, y_pred)\n",
    "    f1 = f1_score(labels, y_pred)\n",
    "    prec = precision_score(labels, y_pred)\n",
    "    rec = recall_score(labels, y_pred)\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": prec, \"recall\": rec}\n",
    "\n",
    "# 4) TrainingArguments (optimized)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=LR,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE*2 if torch.cuda.is_available() else BATCH_SIZE,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    weight_decay=0.01,\n",
    "    fp16=torch.cuda.is_available(),     # mixed precision when GPU present\n",
    "    dataloader_num_workers=4,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    greater_is_better=True,\n",
    "    gradient_accumulation_steps=1,      # increase if you need effective larger batch\n",
    "    logging_steps=200,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# 5) Train\n",
    "trainer.train()\n",
    "\n",
    "# 6) Evaluate on validation and print accuracy\n",
    "eval_result = trainer.evaluate(eval_dataset=val_ds)\n",
    "print(\"Validation metrics:\", eval_result)\n",
    "\n",
    "\n",
    "metrics = trainer.state.log_history\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.DataFrame(metrics)\n",
    "df.plot(x=\"step\", y=\"loss\", title=\"Training Loss\")\n",
    "plt.show()\n",
    "\n",
    "df[['epoch', 'eval_accuracy']].dropna().plot(x='epoch', y='eval_accuracy', marker='o', title='Validation Accuracy')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wQD0IV44LrSs"
   },
   "source": [
    "### Task 3: try the full pipeline (1 point)\n",
    "\n",
    "Finally, it is time to use your model to find duplicate questions.\n",
    "Please implement a function that takes a question and finds top-5 potential duplicates in the training set. For now, it is fine if your function is slow, as long as it yields correct results.\n",
    "\n",
    "Showcase how your function works with at least 5 examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zLSjmsKaUyQb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h86vREj7U02k"
   },
   "source": [
    "__Bonus:__ for bonus points, try to find a way to run the function faster than just passing over all questions in a loop. For isntance, you can form a short-list of potential candidates using a cheaper method, and then run your tranformer on that short list. If you opted for this solution, please keep both the original implementation and the optimized one - and explain briefly what is the difference there."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPsxGMjObURS0kuhIG+rAEF",
   "collapsed_sections": [],
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
